{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Omniglot_One Shot Learning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "nLJSDkR8DNmp",
        "cdAsE9yIgmud",
        "Bf-5_m_tKu6I"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nrajmalwar/Deep-Learning-Projects/blob/master/One-shot%20Learning%20for%20Omniglot%20Dataset/Omniglot_One_Shot_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPZvR7tke-Lq",
        "colab_type": "text"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sGXMTrmavhO",
        "colab_type": "code",
        "outputId": "3b8255c2-c535-4453-c423-40154b1af12a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import cv2\n",
        "import time\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
        "from keras.models import Model\n",
        "from keras.utils import plot_model\n",
        "\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import Concatenate\n",
        "from keras.layers.core import Lambda, Flatten, Dense\n",
        "from keras.initializers import glorot_uniform\n",
        "\n",
        "from keras.engine.topology import Layer\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import numpy.random as rnd\n",
        "\n",
        "from IPython.display import Image"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdiOBoO3fBfB",
        "colab_type": "text"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "628i0DUzbcg4",
        "colab_type": "code",
        "outputId": "d345cdb4-805e-4b29-c171-d899eb00f547",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        }
      },
      "source": [
        "# Download the train and test dataset\n",
        "\n",
        "!wget https://github.com/brendenlake/omniglot/raw/master/python/images_evaluation.zip\n",
        "!wget https://github.com/brendenlake/omniglot/raw/master/python/images_background.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-29 14:16:25--  https://github.com/brendenlake/omniglot/raw/master/python/images_evaluation.zip\n",
            "Resolving github.com (github.com)... 192.30.253.112\n",
            "Connecting to github.com (github.com)|192.30.253.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/brendenlake/omniglot/master/python/images_evaluation.zip [following]\n",
            "--2019-06-29 14:16:25--  https://raw.githubusercontent.com/brendenlake/omniglot/master/python/images_evaluation.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6462886 (6.2M) [application/zip]\n",
            "Saving to: ‘images_evaluation.zip.1’\n",
            "\n",
            "images_evaluation.z 100%[===================>]   6.16M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2019-06-29 14:16:26 (66.4 MB/s) - ‘images_evaluation.zip.1’ saved [6462886/6462886]\n",
            "\n",
            "--2019-06-29 14:16:28--  https://github.com/brendenlake/omniglot/raw/master/python/images_background.zip\n",
            "Resolving github.com (github.com)... 192.30.253.112\n",
            "Connecting to github.com (github.com)|192.30.253.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/brendenlake/omniglot/master/python/images_background.zip [following]\n",
            "--2019-06-29 14:16:28--  https://raw.githubusercontent.com/brendenlake/omniglot/master/python/images_background.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9464212 (9.0M) [application/zip]\n",
            "Saving to: ‘images_background.zip.1’\n",
            "\n",
            "images_background.z 100%[===================>]   9.03M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-06-29 14:16:29 (76.6 MB/s) - ‘images_background.zip.1’ saved [9464212/9464212]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUSngYG4cQhz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unzip the files and save in Colab Disk Storage\n",
        "!unzip -qq 'images_evaluation.zip'\n",
        "!unzip -qq 'images_background.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwow2OdSehrX",
        "colab_type": "code",
        "outputId": "2169f4f5-6cf9-4715-82fc-881bcd68fb35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data\t\t   images_background.zip  images_evaluation.zip\n",
            "images_background  images_evaluation\t  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-knOwlPa9s-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Path for train and validation folder\n",
        "\n",
        "train_folder = 'images_background'\n",
        "val_folder = 'images_evaluation'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_UrhhUZe7SD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadimgs(path, n = 0):\n",
        "    '''\n",
        "    Function: To load the images the images from train or validation directory\n",
        "\n",
        "    Parameters: path- path of the train or validation directory, n - indexing of y_labels\n",
        "    \n",
        "    Return: X - the folder of images of alphabets\n",
        "            y - the labels of images\n",
        "            lang_dict - dictionary of language, the key is the language alphabet and the values are the letters of the alphabet\n",
        "    '''\n",
        "    \n",
        "    X = []\n",
        "    y = []\n",
        "    cat_dict = {}\n",
        "    lang_dict = {}\n",
        "    curr_y = n\n",
        "    \n",
        "    # Load every alphabet from the directory\n",
        "    for alphabet in os.listdir(path):\n",
        "        print(\"loading alphabet: \" + alphabet)\n",
        "        lang_dict[alphabet] = [curr_y, None]\n",
        "        alphabet_path = os.path.join(path, alphabet)\n",
        "        \n",
        "        # Every letter in the alphabet has its own set of images, so load the images individually\n",
        "        for letter in os.listdir(alphabet_path):\n",
        "            cat_dict[curr_y] = (alphabet, letter)\n",
        "            category_images=[]\n",
        "            letter_path = os.path.join(alphabet_path, letter)\n",
        "            \n",
        "            # Read all the images of the particular letter\n",
        "            for filename in os.listdir(letter_path):\n",
        "                image_path = os.path.join(letter_path, filename)\n",
        "                image = plt.imread(image_path)\n",
        "                category_images.append(image)\n",
        "                y.append(curr_y)\n",
        "            try:\n",
        "                X.append(np.stack(category_images))\n",
        "            # edge case  - last one\n",
        "            except ValueError as e:\n",
        "                print(e)\n",
        "                print(\"error - category_images:\", category_images)\n",
        "            curr_y += 1\n",
        "            lang_dict[alphabet][1] = curr_y - 1\n",
        "            \n",
        "    y = np.vstack(y)\n",
        "    X = np.stack(X)\n",
        "    \n",
        "    return X, y, lang_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Os3vJmG7fJye",
        "colab_type": "text"
      },
      "source": [
        "## Load Train Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkcQRjkcfGP5",
        "colab_type": "code",
        "outputId": "4d736f68-8589-4e37-bae9-87a5e48c5a7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        }
      },
      "source": [
        "# Load the train images from the train folder\n",
        "\n",
        "X_train, y_train, c_train = loadimgs(train_folder)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading alphabet: Balinese\n",
            "loading alphabet: Gujarati\n",
            "loading alphabet: Tagalog\n",
            "loading alphabet: Early_Aramaic\n",
            "loading alphabet: Braille\n",
            "loading alphabet: Asomtavruli_(Georgian)\n",
            "loading alphabet: Futurama\n",
            "loading alphabet: Syriac_(Estrangelo)\n",
            "loading alphabet: Alphabet_of_the_Magi\n",
            "loading alphabet: Latin\n",
            "loading alphabet: Blackfoot_(Canadian_Aboriginal_Syllabics)\n",
            "loading alphabet: Malay_(Jawi_-_Arabic)\n",
            "loading alphabet: Anglo-Saxon_Futhorc\n",
            "loading alphabet: Hebrew\n",
            "loading alphabet: Tifinagh\n",
            "loading alphabet: Ojibwe_(Canadian_Aboriginal_Syllabics)\n",
            "loading alphabet: N_Ko\n",
            "loading alphabet: Japanese_(katakana)\n",
            "loading alphabet: Armenian\n",
            "loading alphabet: Grantha\n",
            "loading alphabet: Greek\n",
            "loading alphabet: Sanskrit\n",
            "loading alphabet: Cyrillic\n",
            "loading alphabet: Inuktitut_(Canadian_Aboriginal_Syllabics)\n",
            "loading alphabet: Korean\n",
            "loading alphabet: Japanese_(hiragana)\n",
            "loading alphabet: Bengali\n",
            "loading alphabet: Arcadian\n",
            "loading alphabet: Burmese_(Myanmar)\n",
            "loading alphabet: Mkhedruli_(Georgian)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ga_a5QCLmPCb",
        "colab_type": "code",
        "outputId": "d2fbaace-b6bd-4869-b091-5cc04a41197c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "# The train dataset consists of 30 alphabets. In total, there are 964 classes (or characters). Each class has 20 images of size 105x105.\n",
        "print(X_train.shape) \n",
        "\n",
        "# Total number of images is 964*20 = 19280\n",
        "print(y_train.shape)\n",
        "\n",
        "# Dictionary of the alphabet. Keys are the languages and values are the range of letters\n",
        "print(c_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(964, 20, 105, 105)\n",
            "(19280, 1)\n",
            "{'Balinese': [0, 23], 'Gujarati': [24, 71], 'Tagalog': [72, 88], 'Early_Aramaic': [89, 110], 'Braille': [111, 136], 'Asomtavruli_(Georgian)': [137, 176], 'Futurama': [177, 202], 'Syriac_(Estrangelo)': [203, 225], 'Alphabet_of_the_Magi': [226, 245], 'Latin': [246, 271], 'Blackfoot_(Canadian_Aboriginal_Syllabics)': [272, 285], 'Malay_(Jawi_-_Arabic)': [286, 325], 'Anglo-Saxon_Futhorc': [326, 354], 'Hebrew': [355, 376], 'Tifinagh': [377, 431], 'Ojibwe_(Canadian_Aboriginal_Syllabics)': [432, 445], 'N_Ko': [446, 478], 'Japanese_(katakana)': [479, 525], 'Armenian': [526, 566], 'Grantha': [567, 609], 'Greek': [610, 633], 'Sanskrit': [634, 675], 'Cyrillic': [676, 708], 'Inuktitut_(Canadian_Aboriginal_Syllabics)': [709, 724], 'Korean': [725, 764], 'Japanese_(hiragana)': [765, 816], 'Bengali': [817, 862], 'Arcadian': [863, 888], 'Burmese_(Myanmar)': [889, 922], 'Mkhedruli_(Georgian)': [923, 963]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvx0Blv1f5KM",
        "colab_type": "text"
      },
      "source": [
        "## Load Validation Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nF_UMHhKf6kx",
        "colab_type": "code",
        "outputId": "75359c1f-e613-499c-ee0c-9dc6dd8859b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "# Load the validation images from the validation folder\n",
        "\n",
        "X_val, y_val, c_val = loadimgs(val_folder)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading alphabet: Glagolitic\n",
            "loading alphabet: Sylheti\n",
            "loading alphabet: Angelic\n",
            "loading alphabet: Oriya\n",
            "loading alphabet: Tibetan\n",
            "loading alphabet: Mongolian\n",
            "loading alphabet: Avesta\n",
            "loading alphabet: Atlantean\n",
            "loading alphabet: Syriac_(Serto)\n",
            "loading alphabet: Tengwar\n",
            "loading alphabet: Malayalam\n",
            "loading alphabet: Atemayar_Qelisayer\n",
            "loading alphabet: Old_Church_Slavonic_(Cyrillic)\n",
            "loading alphabet: Ge_ez\n",
            "loading alphabet: Keble\n",
            "loading alphabet: Gurmukhi\n",
            "loading alphabet: ULOG\n",
            "loading alphabet: Aurek-Besh\n",
            "loading alphabet: Manipuri\n",
            "loading alphabet: Kannada\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRT5gg_BnSVH",
        "colab_type": "code",
        "outputId": "1b7edf74-ee4a-4f35-b952-c493241f1603",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "# The train dataset consists of 20 alphabets. In total, there are 659 classes (or characters). Each class has 20 images of size 105x105.\n",
        "print(X_val.shape) \n",
        "\n",
        "# Total number of images is 659*20 = 13180\n",
        "print(y_val.shape)\n",
        "\n",
        "# Dictionary of the alphabet. Keys are the languages and values are the range of letters\n",
        "print(c_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(659, 20, 105, 105)\n",
            "(13180, 1)\n",
            "{'Glagolitic': [0, 44], 'Sylheti': [45, 72], 'Angelic': [73, 92], 'Oriya': [93, 138], 'Tibetan': [139, 180], 'Mongolian': [181, 210], 'Avesta': [211, 236], 'Atlantean': [237, 262], 'Syriac_(Serto)': [263, 285], 'Tengwar': [286, 310], 'Malayalam': [311, 357], 'Atemayar_Qelisayer': [358, 383], 'Old_Church_Slavonic_(Cyrillic)': [384, 428], 'Ge_ez': [429, 454], 'Keble': [455, 480], 'Gurmukhi': [481, 525], 'ULOG': [526, 551], 'Aurek-Besh': [552, 577], 'Manipuri': [578, 617], 'Kannada': [618, 658]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZ_JReBQgKZJ",
        "colab_type": "text"
      },
      "source": [
        "# Build a Siamese Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2Xj_Kzrf_OZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_siamese_model(input_shape):\n",
        "    \"\"\"\n",
        "        Build a Siamese Network Model Architecture based on the paper: http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the tensors for the two input images\n",
        "    \n",
        "    left_input = Input(input_shape)\n",
        "    right_input = Input(input_shape)\n",
        "    \n",
        "    # Sequential model for the Convolutional Neural Network\n",
        "    \n",
        "    model = Sequential()\n",
        "    \n",
        "    # Input Shape = 105x105x1\n",
        "    model.add(Conv2D(64, (10,10), activation='relu', input_shape=input_shape, kernel_regularizer=l2(2e-4))) \n",
        "    # Output Shape: 96x96x64\n",
        "    \n",
        "    model.add(MaxPooling2D())\n",
        "    # Output Shape: 48x48x64\n",
        "    \n",
        "    model.add(Conv2D(128, (7,7), activation='relu', kernel_regularizer=l2(2e-4)))\n",
        "    # Output Shape: 42x42x128\n",
        "    \n",
        "    model.add(MaxPooling2D())\n",
        "    # Output Shape: 21x21x128\n",
        "    \n",
        "    model.add(Conv2D(128, (4,4), activation='relu', kernel_regularizer=l2(2e-4)))\n",
        "    # Output Shape: 18x18x128\n",
        "    \n",
        "    model.add(MaxPooling2D())\n",
        "    # Output Shape: 9x9x128\n",
        "    \n",
        "    model.add(Conv2D(256, (4,4), activation='relu', kernel_regularizer=l2(2e-4)))\n",
        "    # Output Shape: 6x6x256\n",
        "      \n",
        "    model.add(Flatten())    \n",
        "    # Output Shape: 9216x1\n",
        "    \n",
        "    model.add(Dense(4096, activation='sigmoid', kernel_regularizer=l2(1e-3)))\n",
        "    # Output Shape: 4096x1\n",
        "    \n",
        "    # Generate the encodings (feature vectors) for the two images\n",
        "    \n",
        "    encoded_l = model(left_input)\n",
        "    encoded_r = model(right_input)\n",
        "    \n",
        "    # Add a customized layer to compute the absolute difference between the encodings\n",
        "    \n",
        "    L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
        "    L1_distance = L1_layer([encoded_l, encoded_r])\n",
        "    \n",
        "    # Add a dense layer with a sigmoid unit to generate the similarity score\n",
        "    \n",
        "    prediction = Dense(1, activation='sigmoid')(L1_distance)\n",
        "    \n",
        "    # Connect the inputs with the outputs\n",
        "    \n",
        "    siamese_net = Model(inputs = [left_input, right_input], outputs = prediction)\n",
        "    \n",
        "    # Return the model\n",
        "    \n",
        "    return siamese_net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxbABnhcgQjf",
        "colab_type": "code",
        "outputId": "95446201-90f2-444e-8fc8-aee2d76b7ea8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "# Build the model for an input size of 105x105x1\n",
        "\n",
        "model = get_siamese_model((105, 105, 1))\n",
        "\n",
        "# Print the model summary\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 105, 105, 1)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            (None, 105, 105, 1)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_2 (Sequential)       (None, 4096)         38947648    input_3[0][0]                    \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 4096)         0           sequential_2[1][0]               \n",
            "                                                                 sequential_2[2][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1)            4097        lambda_2[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 38,951,745\n",
            "Trainable params: 38,951,745\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVbvKIwGs7d_",
        "colab_type": "code",
        "outputId": "0d9bbfba-fccd-4563-ff71-638abfb17afa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "plot_model(model, show_shapes=True, to_file='model.png')\n",
        "Image('model.png')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4AAAAGVCAIAAAAg0ggBAAAABmJLR0QA/wD/AP+gvaeTAAAgAElE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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLJSDkR8DNmp",
        "colab_type": "text"
      },
      "source": [
        "# Model Compilation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Psjkw-gAga4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use Adam Optimizer with very low learning rate\n",
        "optimizer = Adam(lr = 0.00006)\n",
        "\n",
        "# Compile the model with loss function as binary crossentropy\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdAsE9yIgmud",
        "colab_type": "text"
      },
      "source": [
        "# Load Train Tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OM-Vx7Egf0g",
        "colab_type": "code",
        "outputId": "b42c891e-7c0e-43e0-9bc1-f6dcacca4dcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "print(\"Training alphabets: \\n\")\n",
        "print(list(c_train.keys()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training alphabets: \n",
            "\n",
            "['Cyrillic', 'Hebrew', 'Tagalog', 'Malay_(Jawi_-_Arabic)', 'Futurama', 'Alphabet_of_the_Magi', 'Tifinagh', 'Grantha', 'Mkhedruli_(Georgian)', 'Inuktitut_(Canadian_Aboriginal_Syllabics)', 'Latin', 'Bengali', 'Balinese', 'Sanskrit', 'Korean', 'Gujarati', 'Japanese_(hiragana)', 'N_Ko', 'Arcadian', 'Blackfoot_(Canadian_Aboriginal_Syllabics)', 'Asomtavruli_(Georgian)', 'Braille', 'Ojibwe_(Canadian_Aboriginal_Syllabics)', 'Japanese_(katakana)', 'Syriac_(Estrangelo)', 'Greek', 'Armenian', 'Early_Aramaic', 'Anglo-Saxon_Futhorc', 'Burmese_(Myanmar)']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yI_Iee4ygokr",
        "colab_type": "code",
        "outputId": "1ef6ac53-9abc-453d-8e0d-7db3f3c4a58d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "print(\"Validation alphabets:\", end=\"\\n\\n\")\n",
        "print(list(c_val.keys()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation alphabets:\n",
            "\n",
            "['Oriya', 'Syriac_(Serto)', 'Atlantean', 'Keble', 'Old_Church_Slavonic_(Cyrillic)', 'Glagolitic', 'Tibetan', 'ULOG', 'Ge_ez', 'Manipuri', 'Sylheti', 'Aurek-Besh', 'Tengwar', 'Gurmukhi', 'Kannada', 'Mongolian', 'Malayalam', 'Atemayar_Qelisayer', 'Angelic', 'Avesta']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P58grgIELAgj",
        "colab_type": "text"
      },
      "source": [
        "# Model Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSHTA_8sNKid",
        "colab_type": "text"
      },
      "source": [
        "## get_batch Function\n",
        "\n",
        "1. Function: Create batch of n pairs, half same class, half different class\n",
        "2. Parameters: batch_size- size of the batch;                s - sample from train or validation data\n",
        "3. Return: pairs, targets - Pairs of images and their targets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geHf2d3kgshe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batch(batch_size, s=\"train\"):\n",
        "       \n",
        "    if s == 'train':\n",
        "        X = X_train\n",
        "        categories = c_train\n",
        "    else:\n",
        "        X = X_val\n",
        "        categories = c_val\n",
        "        \n",
        "    n_classes, n_examples, w, h = X.shape\n",
        "\n",
        "    # Randomly sample several classes (each character) to use in the batch\n",
        "    categories = rnd.choice(n_classes, size=(batch_size,), replace=False)\n",
        "    \n",
        "    # Initialize 2 empty arrays for the input image batch\n",
        "    pairs = [np.zeros((batch_size, h, w, 1)) for i in range(2)]\n",
        "    \n",
        "    # Initialize vector for the targets\n",
        "    targets = np.zeros((batch_size,))\n",
        "    \n",
        "    # Make one half of it '1's, so 2nd half of batch has same class\n",
        "    targets[batch_size//2:] = 1\n",
        "    \n",
        "    for i in range(batch_size):\n",
        "        category = categories[i]\n",
        "        idx_1 = rnd.randint(0, n_examples)\n",
        "        pairs[0][i,:,:,:] = X[category, idx_1].reshape(w, h, 1)\n",
        "        idx_2 = rnd.randint(0, n_examples)\n",
        "        \n",
        "        # Pick images of same class for 2nd half, different for 1st half\n",
        "        if i >= batch_size // 2:\n",
        "            category_2 = category  \n",
        "        else: \n",
        "            # Add a random number to the category modulo n classes to ensure 2nd image has a different category\n",
        "            category_2 = (category + rnd.randint(1, n_classes)) % n_classes\n",
        "        \n",
        "        pairs[1][i,:,:,:] = X[category_2, idx_2].reshape(w, h, 1)\n",
        "    \n",
        "    return pairs, targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTGtXePONcNj",
        "colab_type": "text"
      },
      "source": [
        "## generate Function\n",
        "\n",
        "1. Function: A generator function to create batches on the fly, so that model.fit_generator can be used. \n",
        "2. Parametes: batch_size- size of the batch;  s - sample from train or validation data\n",
        "3. Return: (pairs, targets) - tuple of pairs and targets from the get_batch function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WviX865g1T1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate(batch_size, s=\"train\"):\n",
        "        \n",
        "    while True:\n",
        "        pairs, targets = get_batch(batch_size, s)\n",
        "        yield (pairs, targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQGFfyGSNpgd",
        "colab_type": "text"
      },
      "source": [
        "## make_oneshot_task Function\n",
        "1. Function: Create pairs of test image, support set for testing N way one-shot learning\n",
        "2. Parameters: N - value for N way one-shot learning; s - sample from train or validation data; langauge - if True, select characters from that language\n",
        "3. Return: pairs, targets - Pairs and targets\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBhu2zuFg6aU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_oneshot_task(N, s=\"val\", language=None):\n",
        "        \n",
        "    if s == 'train':\n",
        "        X = X_train\n",
        "        categories = c_train\n",
        "    else:\n",
        "        X = X_val\n",
        "        categories = c_val\n",
        "        \n",
        "    n_classes, n_examples, w, h = X.shape\n",
        "    \n",
        "    indices = rnd.randint(0, n_examples, size=(N,))\n",
        "    \n",
        "    if language is not None: # if language is specified, select characters for that language\n",
        "        low, high = categories[language]\n",
        "        \n",
        "        if N > high - low: # incase the language has less than N characters\n",
        "            raise ValueError(\"This language ({}) has less than {} letters\".format(language, N))\n",
        "            \n",
        "        categories = rnd.choice(range(low,high), size=(N,), replace=False)\n",
        "\n",
        "    else: # if no language specified just pick a bunch of random letters\n",
        "        categories = rnd.choice(range(n_classes), size=(N,), replace=False)\n",
        "        \n",
        "    true_category = categories[0]\n",
        "    ex1, ex2 = rnd.choice(n_examples, replace=False, size=(2,))\n",
        "    test_image = np.asarray([X[true_category, ex1, :, :]]*N).reshape(N, w, h, 1)\n",
        "    support_set = X[categories, indices, :, :]\n",
        "    support_set[0,:,:] = X[true_category, ex2]\n",
        "    support_set = support_set.reshape(N, w, h, 1)\n",
        "    targets = np.zeros((N,))\n",
        "    targets[0] = 1\n",
        "    targets, test_image, support_set = shuffle(targets, test_image, support_set)\n",
        "    pairs = [test_image, support_set]\n",
        "\n",
        "    return pairs, targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU6PyHiJN8ct",
        "colab_type": "text"
      },
      "source": [
        "# test_oneshot Function\n",
        "1. Function: Test average N way oneshot learning accuracy of a siamese neural net over k one-shot tasks\n",
        "2. Parameters: model - The Siamese model to be passed to the network; N - The value N way one-shot learning; k - Number of the times one-shot tasks are performed (number of times images are compared)\n",
        "3. Return: percent_correct - Percentage of correct predictions in k tasks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGIA4DI4g8x0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_oneshot(model, N, k, s = \"val\", verbose = 0):\n",
        "        \n",
        "    n_correct = 0\n",
        "    \n",
        "    if verbose:\n",
        "        print(\"Evaluating model on {} random {} way one-shot learning tasks ... \\n\".format(k,N))\n",
        "        \n",
        "    for i in range(k):\n",
        "        inputs, targets = make_oneshot_task(N,s)\n",
        "        probs = model.predict(inputs)\n",
        "        if np.argmax(probs) == np.argmax(targets):\n",
        "            n_correct+=1\n",
        "     \n",
        "    percent_correct = (100.0 * n_correct / k)\n",
        "        \n",
        "    if verbose:\n",
        "        print(\"Got an average of {}% {} way one-shot learning accuracy \\n\".format(percent_correct, N))\n",
        "    return percent_correct"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bf-5_m_tKu6I",
        "colab_type": "text"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZZWhKpohAC7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "\n",
        "# Interval for evaluating on one-shot tasks\n",
        "evaluate_every = 200 \n",
        "\n",
        "# Batch size\n",
        "batch_size = 32\n",
        "\n",
        "# No. of training iterations\n",
        "n_iter = 15000 \n",
        "\n",
        "# How many classes for Testing one-shot tasks\n",
        "N_way = 20\n",
        "\n",
        "# How many one-shot tasks to validate on\n",
        "n_val = 250 \n",
        "\n",
        "best = -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWHC5yBFhCj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create directory to save Model weights\n",
        "!mkdir 'weights'\n",
        "model_path = 'weights/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gqqx23ZOhLZY",
        "colab_type": "code",
        "outputId": "1eb45697-aecf-4e6f-b34a-75c5ea23285d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11995
        }
      },
      "source": [
        "print(\"Starting training process!\")\n",
        "print(\"-------------------------------------\")\n",
        "t_start = time.time()\n",
        "\n",
        "for i in range(1, n_iter+1):\n",
        "    (inputs, targets) = get_batch(batch_size)\n",
        "    \n",
        "    #Train the model batch-wise\n",
        "    loss = model.train_on_batch(inputs, targets)\n",
        "    \n",
        "    if i % evaluate_every == 0:\n",
        "        print(\"\\n ------------- \\n\")\n",
        "        print(\"Time for {0} iterations: {1} mins\".format(i, (time.time()-t_start)/60.0))\n",
        "        print(\"Train Loss: {0}\".format(loss)) \n",
        "        val_acc = test_oneshot(model, N_way, n_val, verbose=True)\n",
        "        model.save_weights(os.path.join(model_path, 'weights.{}.h5'.format(i)))\n",
        "        \n",
        "        if val_acc >= best:\n",
        "            print(\"Current best: {0}, previous best: {1}\".format(val_acc, best))\n",
        "            best = val_acc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting training process!\n",
            "-------------------------------------\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 200 iterations: 0.31349500417709353 mins\n",
            "Train Loss: 0.32489266991615295\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 60.0% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 60.0, previous best: -1\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 400 iterations: 0.6974383393923441 mins\n",
            "Train Loss: 0.3876653015613556\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 64.0% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 64.0, previous best: 60.0\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 600 iterations: 1.0778248111406963 mins\n",
            "Train Loss: 0.2776261866092682\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 65.6% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 65.6, previous best: 64.0\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 800 iterations: 1.4556678136189778 mins\n",
            "Train Loss: 0.20410972833633423\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 72.8% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 72.8, previous best: 65.6\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 1000 iterations: 1.8343061844507853 mins\n",
            "Train Loss: 0.22089748084545135\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 66.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 1200 iterations: 2.2142274141311646 mins\n",
            "Train Loss: 0.2086174637079239\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 66.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 1400 iterations: 2.592349092165629 mins\n",
            "Train Loss: 0.17075401544570923\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 64.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 1600 iterations: 2.970634917418162 mins\n",
            "Train Loss: 0.23286525905132294\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 68.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 1800 iterations: 3.347906494140625 mins\n",
            "Train Loss: 0.3809426426887512\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 73.6% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 73.6, previous best: 72.8\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 2000 iterations: 3.7249138792355856 mins\n",
            "Train Loss: 0.265053391456604\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 73.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 2200 iterations: 4.101535741488139 mins\n",
            "Train Loss: 0.25135788321495056\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 66.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 2400 iterations: 4.477994159857432 mins\n",
            "Train Loss: 0.20173679292201996\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 67.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 2600 iterations: 4.855037772655487 mins\n",
            "Train Loss: 0.23428025841712952\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 68.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 2800 iterations: 5.232023195425669 mins\n",
            "Train Loss: 0.2912027835845947\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 75.6% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 75.6, previous best: 73.6\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 3000 iterations: 5.609003412723541 mins\n",
            "Train Loss: 0.24780982732772827\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 67.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 3200 iterations: 5.985818537076314 mins\n",
            "Train Loss: 0.33832862973213196\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 66.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 3400 iterations: 6.363222773869833 mins\n",
            "Train Loss: 0.20689323544502258\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 64.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 3600 iterations: 6.740370980898539 mins\n",
            "Train Loss: 0.21692052483558655\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 75.6% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 75.6, previous best: 75.6\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 3800 iterations: 7.117495389779409 mins\n",
            "Train Loss: 0.2996314764022827\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 73.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 4000 iterations: 7.49486133257548 mins\n",
            "Train Loss: 0.24808569252490997\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 70.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 4200 iterations: 7.871880908807118 mins\n",
            "Train Loss: 0.35774287581443787\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 64.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 4400 iterations: 8.249247133731842 mins\n",
            "Train Loss: 0.21523986756801605\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 72.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 4600 iterations: 8.625820787747701 mins\n",
            "Train Loss: 0.22363819181919098\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 68.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 4800 iterations: 9.002613588174183 mins\n",
            "Train Loss: 0.3241546154022217\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 71.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 5000 iterations: 9.378715709845226 mins\n",
            "Train Loss: 0.27120518684387207\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 68.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 5200 iterations: 9.755321685473124 mins\n",
            "Train Loss: 0.19582369923591614\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 71.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 5400 iterations: 10.132545292377472 mins\n",
            "Train Loss: 0.21239881217479706\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 69.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 5600 iterations: 10.511578182379404 mins\n",
            "Train Loss: 0.23587311804294586\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 70.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 5800 iterations: 10.893213828404745 mins\n",
            "Train Loss: 0.25916141271591187\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 74.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 6000 iterations: 11.272408258914947 mins\n",
            "Train Loss: 0.2642616927623749\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 65.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 6200 iterations: 11.651574250062307 mins\n",
            "Train Loss: 0.2688080966472626\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 72.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 6400 iterations: 12.030444912115733 mins\n",
            "Train Loss: 0.24234585464000702\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 74.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 6600 iterations: 12.408229581514995 mins\n",
            "Train Loss: 0.2694398760795593\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 66.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 6800 iterations: 12.786205486456554 mins\n",
            "Train Loss: 0.30527621507644653\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 72.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 7000 iterations: 13.164647634824117 mins\n",
            "Train Loss: 0.27218905091285706\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 73.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 7200 iterations: 13.541939377784729 mins\n",
            "Train Loss: 0.28055906295776367\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 74.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 7400 iterations: 13.91890409787496 mins\n",
            "Train Loss: 0.31519371271133423\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 70.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 7600 iterations: 14.294987241427103 mins\n",
            "Train Loss: 0.21325412392616272\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 73.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 7800 iterations: 14.670634086926778 mins\n",
            "Train Loss: 0.25344207882881165\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 71.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 8000 iterations: 15.04687020778656 mins\n",
            "Train Loss: 0.18135593831539154\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 75.6% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 75.6, previous best: 75.6\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 8200 iterations: 15.42194435596466 mins\n",
            "Train Loss: 0.20104818046092987\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 69.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 8400 iterations: 15.797480567296345 mins\n",
            "Train Loss: 0.2536768615245819\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 76.8% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 76.8, previous best: 75.6\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 8600 iterations: 16.17310758034388 mins\n",
            "Train Loss: 0.19342251121997833\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 72.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 8800 iterations: 16.549128524462382 mins\n",
            "Train Loss: 0.22744981944561005\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 71.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 9000 iterations: 16.924575622876485 mins\n",
            "Train Loss: 0.27926039695739746\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 71.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 9200 iterations: 17.300443927447002 mins\n",
            "Train Loss: 0.17421217262744904\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 77.2% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 77.2, previous best: 76.8\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 9400 iterations: 17.6759911775589 mins\n",
            "Train Loss: 0.24964004755020142\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.0% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 78.0, previous best: 77.2\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 9600 iterations: 18.052112531661987 mins\n",
            "Train Loss: 0.25580543279647827\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 79.6% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 79.6, previous best: 78.0\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 9800 iterations: 18.42878306309382 mins\n",
            "Train Loss: 0.1768854707479477\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 70.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 10000 iterations: 18.805558117230735 mins\n",
            "Train Loss: 0.18820162117481232\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 73.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 10200 iterations: 19.181118083000182 mins\n",
            "Train Loss: 0.22595153748989105\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 74.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 10400 iterations: 19.56123860279719 mins\n",
            "Train Loss: 0.17393335700035095\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 76.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 10600 iterations: 19.937785983085632 mins\n",
            "Train Loss: 0.20341049134731293\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 70.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 10800 iterations: 20.314004039764406 mins\n",
            "Train Loss: 0.17671605944633484\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 77.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 11000 iterations: 20.689597078164418 mins\n",
            "Train Loss: 0.17822280526161194\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.8% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 80.8, previous best: 79.6\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 11200 iterations: 21.066193521022797 mins\n",
            "Train Loss: 0.17425274848937988\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 72.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 11400 iterations: 21.44207482735316 mins\n",
            "Train Loss: 0.20024776458740234\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 70.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 11600 iterations: 21.81872994105021 mins\n",
            "Train Loss: 0.19773219525814056\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 76.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 11800 iterations: 22.196578633785247 mins\n",
            "Train Loss: 0.22489017248153687\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 72.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 12000 iterations: 22.573040795326232 mins\n",
            "Train Loss: 0.2504946291446686\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 68.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 12200 iterations: 22.949238618214924 mins\n",
            "Train Loss: 0.184208944439888\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 77.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 12400 iterations: 23.325260881582896 mins\n",
            "Train Loss: 0.22136881947517395\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 71.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 12600 iterations: 23.702403887112936 mins\n",
            "Train Loss: 0.2767176330089569\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 68.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 12800 iterations: 24.079189892609914 mins\n",
            "Train Loss: 0.20761805772781372\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 13000 iterations: 24.456442213058473 mins\n",
            "Train Loss: 0.23424501717090607\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 74.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 13200 iterations: 24.833107610543568 mins\n",
            "Train Loss: 0.18000157177448273\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 82.0% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 82.0, previous best: 80.8\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 13400 iterations: 25.211142257849374 mins\n",
            "Train Loss: 0.1521998643875122\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 74.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 13600 iterations: 25.588320922851562 mins\n",
            "Train Loss: 0.18588446080684662\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 13800 iterations: 25.966525840759278 mins\n",
            "Train Loss: 0.22632548213005066\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 14000 iterations: 26.34373813867569 mins\n",
            "Train Loss: 0.20481082797050476\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 75.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 14200 iterations: 26.720007701714835 mins\n",
            "Train Loss: 0.13311298191547394\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 77.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 14400 iterations: 27.096813901265463 mins\n",
            "Train Loss: 0.2394743263721466\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 72.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 14600 iterations: 27.473583920796713 mins\n",
            "Train Loss: 0.23853012919425964\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 77.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 14800 iterations: 27.85048307975133 mins\n",
            "Train Loss: 0.28304120898246765\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 70.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 15000 iterations: 28.227285881837208 mins\n",
            "Train Loss: 0.15626409649848938\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 74.0% 20 way one-shot learning accuracy \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJImaBO3ni2P",
        "colab_type": "text"
      },
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhAesFH6nmBN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(os.path.join(model_path, \"weights.15000.h5\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBpAnpNZOR4n",
        "colab_type": "text"
      },
      "source": [
        "## concat_images Function\n",
        "\n",
        "1. Function: Concatenates a bunch of images into a big matrix for plotting purposes\n",
        "2. Parameters: X - input images\n",
        "3. Return: img - Concatenated image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36U07BvWhNjj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def concat_images(X):\n",
        "    \n",
        "    nc, h , w, _ = X.shape\n",
        "    X = X.reshape(nc, h, w)\n",
        "    n = np.ceil(np.sqrt(nc)).astype(\"int8\")\n",
        "    img = np.zeros((n*w,n*h))\n",
        "    x = 0\n",
        "    y = 0\n",
        "    for example in range(nc):\n",
        "        img[x*w:(x+1)*w, y*h:(y+1)*h] = X[example]\n",
        "        y += 1\n",
        "        if y >= n:\n",
        "            y = 0\n",
        "            x += 1\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PH5CPjHAOawK",
        "colab_type": "text"
      },
      "source": [
        "## plot_oneshot_task Function\n",
        "1. Function: Plot the images of N way one-shot learning pairs\n",
        "2. Parameters: pairs - pairs of images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_YzqXrfiMuE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_oneshot_task(pairs):\n",
        "    \n",
        "    fig,(ax1,ax2) = plt.subplots(nrows=1, ncols=2)\n",
        "    ax1.matshow(pairs[0][0].reshape(105,105), cmap='gray')\n",
        "    img = concat_images(pairs[1])\n",
        "    ax1.get_yaxis().set_visible(False)\n",
        "    ax1.get_xaxis().set_visible(False)\n",
        "    ax2.matshow(img, cmap='gray')\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSlKmr4RiPGT",
        "colab_type": "code",
        "outputId": "8f3a87eb-72fe-4576-9b7a-fdc7dc3954d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "# Plot 20 way one-shot learning pair for Sanskrit Language\n",
        "pairs, targets = make_oneshot_task(20, \"train\", \"Sanskrit\")\n",
        "plot_oneshot_task(pairs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAACtCAYAAACOYKWSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAACa5JREFUeJzt3V2SpLgVBtBKh5fQfnYvove/gu49\ntJ/de8h5cKRDxvwIkHQldE6EY8ZTVQlJwsflokSv9/v9BUB7f4teAYBZCWCAIAIYIIgABggigAGC\nCGCAIAIYIIgABggigAGC/H3vh9++fXt///690aowm9+/f3/9+fPnFbFs+zY15e7buwH8/fv3r58/\nf5ZbK0j8+PEjbNn2bWrK3bd3Axjow+t17ULBs176pgcMDyV8+6cChoo+levdMMz5+9fr9ejQzbkK\nGO39C2BIXL3U57rW2/zM8moHugCGxJ0D7ukVaCtH2/Dqdl4L3vR11n6+FdalPmcBDB07Co0ar39m\nWcsWy5VwbH3S2lpe7ntd/nvO324RwFBQySp4rX/8er2qVNprr7e2rK3AHqF1U2qbldz2AhgO5FaJ\n7/e7eBAtD/atZbQKwOX6lLrJOCsBDCfkVIMlnHntEarPK3q5OZd+5qVPNAIYDuz1DGu0BM5UlbVC\nKirUI5Z7tMya6ySAoYDarYe15azdALuynOVJJH3dWj3nNbknnprr1LqVIoDhhk9I3QnBK0r2XtOg\nnVH62d0dFXKWAIZBpOHQYhREr2rc7Fy+7tbNxtIEMNxQswe7NgJiz0gh2qujfn9pAhhOqP3FiJkt\nWyE9btfSvWdPQ4OL3u/3I24E9dT/Tbdpq9EJke9dAMMJn4DosTq7axlEPVeipUWFsBYEFFbqMrXV\n8K+9UQBR4duy312rv5tDBQwdaj2sLV3m1v/f+punVMh727rW1YAAhk5FBNtTwvSsrRNe7ZuCWhBQ\n0BPG57b+BlxvWrZhBDDwf2YM4Yj3KYCBVbMEbyQ9YIAgAhggiAAGCCKAAYIIYIAgAhggiAAGCCKA\nAYIIYIAgvgkHk9t7CljODMV7vzfTV5mvEMAwub3wzH0c5t3HZpZ47OaIQS+AgVU5gVaqwr1baee6\nGvS1wl0AQ2dyQyK64utlHrm70mcBb01Hf/Rer34WAhgGVSsUzii9jNqhfnZ909/fWrc720AAw4q7\nQXDnoDzzt+mleURFWvIm27LN0FuF/dnGJU86AhhWrB1kWzMl9DJ7cMnlnwm/kqGUvk7E9mw9akMA\nw0nRQVtTb1Xn0wlgGMBaMNbuv7YambC3DktPO/n5Jhx0bG8sbskATF+r55ArVaHXuKF2hQoYOpUT\nsDVbBq37oTkVd41qO72B2boFowKGgdUKyJ6r4BJyhpctf7/GNlEBw0DSsCgZCOk09JG23l+N9VoO\n3TMtPdWd2ZGfXgUdOeq91nYUiqVvgl0JpJr7SIvhfVHjpz8EMKxYO/i3AqFlIC+VXvbZsGvRJ+5l\nnHUNjwjg6Msmni8yBHoNnhrrtXWSaVEFRzw600042JG2AHoMwh7XqYZlkRVd+ZcigGFFetc7amys\nK7v/aPlsCMPQoCO5N6JmqUSjpCFcKySNggD+a20UxMxBH/14zRrBL4AnNPNBPJrl5XfP/WjOE8Aw\nAIEbzzfhNoywc96ZeRZ4JjfhAIIIYIAgAhggiAAGCCKAAYIIYIAgAhgG1MPD07lPAMPABPHYHvFF\nDJjN8kHxEc+yvavWNEO1ldzWAhgSpUKh9WzCI4ZwjcdMltwGe+tVajkCGBJpKORMk57+TaTlk9N6\nWKdcV6ZBuvJ3R6+3p9b2FMDQgaMQyJmqJ51gssQjLO9WpiOdBD5az/cngDeYPZgIWwHQYobmkq91\n55hYW4/ac8JFEcCJqzugB2Zz19Z+s9YnPZqp+eol+lH1V3vCzJyea/o7I7ZblgxDgwGk89O1XuZH\nzcvxNEzX/re2/JZzxdUyfQVc+sNTDVPTXt93dFvHyxMq3S3TVsAtBrAbJM/olpV36/05J3xHDubp\nK2DgWNqDbTneuOUkmVstjprvdcoAjjqLQwmR+1PNlkf0F0m2JkCtaaoWxNmWwNYNgZEvecjXy4lz\na79ttS+utR9Kb5uzLY6afeGWx/dUAQy5jgKhZTjnjApYu/lbY1xvzRBOXzf65NcqhKdsQezJ3fBr\n4y55luXXe6mrt2FlLXreAjhxdSML4+dqFQpnL6kjhp9tfRGjxXLu/N4dtUNYAEOGVuFzxdY3xOif\nHnBhbtRxRVpp5wTo3u/MvO/VaBnVvApSAVfUW0+Lvp0N4ZmDds9IIyNUwNCZnCuoHsK3t8Kit/XJ\noQJuYO+GSQ8HEn26s2+0HB8cpfVjK2sQwI0sR0qMtqPQt9n2p6e8Xy2IAE/ZeYB7BDDc4GTKHQIY\nLhK+3CWAAYIIYIAgAhggiAAGCCKAAYIIYIAgvgkHE6v15DDyCGAgyzJcfaX+PgHM9EaqAktPRilA\nYwlgppcbQtEVX+6sF72H6p2TSI33fXam9JIEMHTibCXee9AeKXXlcXc75E6cYE64ytam9oZWcva5\n0i2ICHvz6x29r5rvP+KRsQJ4Q62n64984PC/nhCGPZh5OwrgxpbBPuNON4IzJ+Ba1VL0FDu5k4OW\neO+9HAet+/wCGBJHoRMxDc6yR9lLWH19lVuX6Bucn3VI/9nCVAHc4yzFKuI+rY15Xf739ICt9bml\nr1trGUfrv/Wz0jfRIo+F9PNtmQ9TfhX5M+tsj2GXOyU59WyF79HvcU/U9lyeXLUgYABOlGX12GKp\n7VEV8JUDIq2GZ/rgWZfTejj6mxZKh7+TSYzhK+DljnP3LFqzz8bz1A7fvf5sixtXrU8ue8t74jE0\nfABDLSW+MnsnwD43hGr3oI+W04MWN8ki3v+jWhCp3nYmrY6xnP1mVi1b+0vpfajFMnKsnQhabOMo\nKmBYkXNQppXjE1oBZ5dR4ySwNRa39fZtVcAJYLhhhMv3kcx2dfjoAJ5xWAvtpZWbfY0zHtsDTqlO\nKOFoKJrwbeNJ23mKAAY4o1XIDx/ATzobAnMZPoC/vvIu/7QhgN48IoBzuVsN9GSqAAboyaMC+Mzs\ntgDRHjcOuMeHrtOfX79+2UcI96gKGGAk0wawG3JAtMcGsPHBQO8eG8AAvXvcTbhUzg259GctqmZt\nD+Dj0QF81l443glnoQus0YIACDJFBVxiHqlWVaybhzCPaSrgEYJthHUEypkmgAF6M0UL4iOtMHu5\nMabqhXlNFcCpyGdGCF3g60sLAiDMtBXwR041WqJKVvUCS9MHcA7hCdSgBQEQRAADBBHAAEEEMEAQ\nAQwQRAADBBHAAEEEMEAQAQwQRAADBBHAAEEEMEAQAQwQRAADBBHAAEFee8+6fb1e//76+vpXu9Vh\nMv98v9//iFiwfZvKsvbt3QAGoB4tCIAgAhggiAAGCCKAAYIIYIAgAhggiAAGCCKAAYIIYIAgfwGL\nd62nz4flhgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ymcgasWjJii",
        "colab_type": "code",
        "outputId": "87a8a17a-1be7-4994-8bed-daa78b052977",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# Evaluate the accuracy for 250 random 20 way One-shot learning tasks\n",
        "\n",
        "acc = test_oneshot(model, 20, 250, s='Sanskrit', verbose=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 71.6% 20 way one-shot learning accuracy \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}